{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import os\n",
    "import sys\n",
    "import umap\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../profiling/\")\n",
    "import profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = \"/raid/data/cellpainting/TAORF/\"\n",
    "EXP = \"taorf_efn_128_newindex\"\n",
    "NUM_FEATURES = 6400\n",
    "OUTPUT_FILE = \"data/well_level_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "meta = pd.read_csv(os.path.join(PROJECT_ROOT, \"inputs/metadata/index.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17227/17227 [03:12<00:00, 89.61it/s] \n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for i in tqdm(meta.index):\n",
    "    filename = PROJECT_ROOT + \"outputs/\" + EXP + \"/features/{}/{}_{}.npz\"\n",
    "    filename = filename.format(\n",
    "        meta.loc[i, \"Metadata_Plate\"], \n",
    "        meta.loc[i, \"Metadata_Well\"], \n",
    "        meta.loc[i, \"Metadata_Site\"]\n",
    "    )\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename, \"rb\") as data:\n",
    "            info = np.load(data)\n",
    "            features.append(info[\"features\"])\n",
    "    else:\n",
    "        features.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images 17227 (22, 6400)\n",
      "Total single cells: 883098\n"
     ]
    }
   ],
   "source": [
    "total_single_cells = 0\n",
    "for i in range(len(features)):\n",
    "    if len(features[i]) > 0:\n",
    "        total_single_cells += features[i].shape[0]\n",
    "\n",
    "print(\"Total images\",len(features),features[0].shape)\n",
    "print(\"Total single cells:\", total_single_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Site-level profiles / Median Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:07<00:00, 25.52s/it]\n"
     ]
    }
   ],
   "source": [
    "site_level_data = []\n",
    "site_level_features = []\n",
    "for plate in tqdm(meta[\"Metadata_Plate\"].unique()):\n",
    "    m1 = meta[\"Metadata_Plate\"] == plate\n",
    "    wells = meta[m1][\"Metadata_Well\"].unique()\n",
    "    for well in wells:\n",
    "        result = meta.query(\"Metadata_Plate == '{}' and Metadata_Well == '{}'\".format(plate, well))\n",
    "        for i in result.index:\n",
    "            if len(features[i]) == 0:\n",
    "                continue\n",
    "            num_features = features[i].shape[1]\n",
    "            mean_profile = np.median(features[i], axis=0)\n",
    "            pert_name = result[\"pert_name\"].unique()\n",
    "            replicate = result[\"pert_name_replicate\"].unique()\n",
    "            broad_sample = result[\"broad_sample\"].unique()\n",
    "            if len(pert_name) > 1:\n",
    "                print(pert_name)\n",
    "            site_level_data.append(\n",
    "                {\n",
    "                    \"Plate\": plate,\n",
    "                    \"Well\": well,\n",
    "                    \"pert_name\": pert_name[0],\n",
    "                    \"Replicate\": replicate[0],\n",
    "                    \"broad_sample\": broad_sample[0]\n",
    "                }\n",
    "            )\n",
    "            site_level_features.append(mean_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1 = [\"Plate\", \"Well\", \"pert_name\", \"Replicate\", \"broad_sample\"]\n",
    "columns2 = [i for i in range(num_features)]\n",
    "\n",
    "sites1 = pd.DataFrame(columns=columns1, data=site_level_data)\n",
    "sites2 = pd.DataFrame(columns=columns2, data=site_level_features)\n",
    "sites = pd.concat([sites1, sites2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Well-level profiles / Mean Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse well data\n",
    "wells = sites.groupby([\"Plate\", \"Well\", \"pert_name\"]).mean().reset_index()\n",
    "\n",
    "tmp = meta.groupby([\"Metadata_Plate\", \"Metadata_Well\", \"pert_name\", \"broad_sample\"])[\"DNA\"].count().reset_index()\n",
    "wells = pd.merge(wells, tmp, how=\"left\", left_on=[\"Plate\", \"Well\", \"pert_name\"], right_on=[\"Metadata_Plate\", \"Metadata_Well\", \"pert_name\"])\n",
    "\n",
    "wells = wells[columns1 + columns2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400,) (6400, 6400)\n"
     ]
    }
   ],
   "source": [
    "whN = profiling.WhiteningNormalizer(wells.loc[wells[\"pert_name\"] == \"EMPTY_\", columns2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "whD = whN.normalize(wells[columns2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save whitened profiles\n",
    "wells[columns2] = whD\n",
    "wells.to_csv(OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Treatment-level profiles / Mean Aggreagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate profiles\n",
    "columns1 = [\"Plate\", \"Well\", \"pert_name\", \"Replicate\", \"broad_sample\"]\n",
    "columns2 = [i for i in range(NUM_FEATURES)] \n",
    "profiles = wells.groupby(\"pert_name\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover broad_sample column (cannot be used in groupby because it contains NaN values)\n",
    "tmp = wells.groupby([\"pert_name\", \"broad_sample\"])[\"Replicate\"].count().reset_index()\n",
    "profiles = pd.merge(profiles.reset_index(), tmp, on=\"pert_name\", how=\"left\")\n",
    "profiles = profiles[[\"pert_name\", \"broad_sample\"] + columns2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove samples without MOA (according to [1])\n",
    "Y = pd.read_csv(\"data/TAORF_MOA_MATCHES.csv\")\n",
    "profiles = pd.merge(profiles, Y, left_on=\"broad_sample\", right_on=\"Var1\")\n",
    "profiles = profiles[[\"pert_name\", \"broad_sample\", \"Metadata_moa.x\"] + columns2].sort_values(by=\"broad_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Pearson correlation\n",
    "CRM = np.corrcoef(profiles[columns2])\n",
    "\n",
    "# Transform to tidy format\n",
    "df = pd.DataFrame(data=CRM, index=list(profiles.broad_sample), columns=list(profiles.broad_sample))\n",
    "df = df.reset_index().melt(id_vars=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate rows\n",
    "df2 = pd.merge(\n",
    "    df, \n",
    "    profiles[[\"broad_sample\", \"Metadata_moa.x\"]], \n",
    "    how=\"left\", \n",
    "    left_on=\"index\", # <=== Rows\n",
    "    right_on=\"broad_sample\"\n",
    ").drop(\"broad_sample\",axis=1)\n",
    "\n",
    "# Annotate columns\n",
    "df2 = pd.merge(\n",
    "    df2, profiles[[\"broad_sample\", \"Metadata_moa.x\"]],\n",
    "    how=\"left\", \n",
    "    left_on=\"variable\", # <=== Columns\n",
    "    right_on=\"broad_sample\"\n",
    ").drop(\"broad_sample\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and save\n",
    "df2.columns = [\"Var1\", \"Var2\", \"value\", \"Metadata_moa.x\", \"Metadata_moa.y\"]\n",
    "df2.to_csv(\"data/correlation_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
