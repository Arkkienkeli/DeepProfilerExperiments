{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOA Evaluation using enrichment analysis\n",
    "\n",
    "- Adopted here: https://www.nature.com/articles/s41467-019-10154-8\n",
    "- Explained here: https://yulab-smu.github.io/clusterProfiler-book/chapter2.html\n",
    "\n",
    "### Procedure:\n",
    "1. Compute similarity / correlation / affinity matrix\n",
    "1. Define MOA matching criteria based on metadata\n",
    "  - https://github.com/carpenterlab/2018_rohban_natcomm/blob/master/code/moa_evaluations.R#L67\n",
    "  - https://github.com/carpenterlab/2018_rohban_natcomm/blob/master/code/evaluate.R#L190\n",
    "1. Find the threshold of top connections (percentile)\n",
    "1. Run enrichment analysis (one-sided version of Fisher's exact test)\n",
    "  - https://github.com/carpenterlab/2018_rohban_natcomm/blob/master/code/moa_evaluations.R#L97\n",
    "  - https://github.com/carpenterlab/2018_rohban_natcomm/blob/master/code/evaluate.R#L205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "sys.path.append(\"../profiling/\")\n",
    "import metrics\n",
    "import quality\n",
    "import profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SIM_MATRIX = \"data/cos_efn128combinedplatesout_conv6a_1e-2_e30.csv\"\n",
    "OUT_RESUTS = \"data/efn128combinedplatesout_conv6a_1e-2_e30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = profiling.load_similarity_matrix(SIM_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOA matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.groupby(\"Metadata_moa.x\")[\"Var1\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "moa_matches = []\n",
    "Y[\"Ref_moa\"] = Y[\"Metadata_moa.x\"].str.replace('|', '___')\n",
    "for k,r in Y.iterrows():\n",
    "    moas = r[\"Metadata_moa.x\"].split(\"|\")\n",
    "    candidates = []\n",
    "    for m in moas:\n",
    "        reg = r'(^|___){}($|___)'.format(m)\n",
    "        candidates.append(Y[\"Ref_moa\"].str.contains(reg))\n",
    "    matches = candidates[0]\n",
    "    for c in candidates:\n",
    "        matches = matches | c\n",
    "    moa_matches.append(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_matches = np.asarray(moa_matches)\n",
    "plt.imshow(moa_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "SIM = np.asarray(X[Y.Var1])\n",
    "is_query = moa_matches.sum(axis=0) > 1\n",
    "\n",
    "for i in range(SIM.shape[0]):\n",
    "    if is_query[i]:\n",
    "        idx = [x for x in range(SIM.shape[1]) if x != i]\n",
    "        results[i] = quality.enrichment_analysis(SIM[i,idx], moa_matches[i,idx], 99.)\n",
    "        if results[i][\"ods_ratio\"] is np.nan:\n",
    "            print(results[i][\"V\"], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folds = [results[x][\"ods_ratio\"] for x in results]\n",
    "print(\"Average folds of enrichment at top 1%:\", np.mean(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enrichment_results = pd.DataFrame(data=results).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average precision analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def precision_at_k(sim_matrix, moa_matches, rank_pos=None):\n",
    "    results = {}\n",
    "    is_query = moa_matches.sum(axis=0) > 1\n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i]:\n",
    "            ranking = np.argsort(-sim_matrix[i,idx])\n",
    "            pk = metrics.precision_at_k(moa_matches[i, ranking[1:]], rank_pos)\n",
    "            results[i] = {\"precision_at_k\":pk,\"pk\":rank_pos}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positions = [x for x in range(5,55,5)]\n",
    "average_precision_at_k = []\n",
    "for pos in positions:\n",
    "    prec_k = precision_at_k(SIM, moa_matches, pos)\n",
    "    average_precision_at_k.append(np.mean([prec_k[q][\"precision_at_k\"] for q in prec_k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(positions, average_precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top_1percent = max(int(X.shape[0]*0.01), 1)\n",
    "top_prec = precision_at_k(SIM, moa_matches, top_1percent)\n",
    "avg_top_prec = np.mean([top_prec[q][\"precision_at_k\"] for q in top_prec])\n",
    "print(f\"Average of Precision At Top 1% ({top_1percent} results) => \", avg_top_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prec_at_top1 = pd.DataFrame(data=top_prec).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recall_at(sim_matrix, moa_matches, rank_pos=None):\n",
    "    results = {}\n",
    "    is_query = moa_matches.sum(axis=0) > 1\n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i]:\n",
    "            ranking = np.argsort(-sim_matrix[i,:])\n",
    "            rc = np.sum(moa_matches[i, ranking[1:rank_pos]]) / np.sum(moa_matches[i,:])\n",
    "            results[i] = {\"recall_at_k\":rc, \"rk\":rank_pos}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall = []\n",
    "for pos in positions:\n",
    "    recall_k = recall_at(SIM, moa_matches, pos)\n",
    "    recall.append(np.mean([recall_k[x][\"recall_at_k\"] for x in recall_k]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(positions, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall_top_10 = recall_at(SIM, moa_matches, top_1percent*10)\n",
    "avg_recall_at_top = np.mean([recall_top_10[x][\"recall_at_k\"] for x in recall_top_10])\n",
    "print(f\"Average Recall At Top 10% ({top_1percent*10} results) => \", avg_recall_at_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall_at_top10 = pd.DataFrame(data=recall_top_10).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolated Recall-Precision Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall_axis, average_precision = metrics.interpolated_precision_recall_curve(moa_matches, SIM)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(recall_axis, average_precision)\n",
    "\n",
    "print(\"Mean Average Precision (MAP): \\t\", np.mean(average_precision))\n",
    "print(\"Area Under the PR curve: \\t\", sklearn.metrics.auc(recall_axis, average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"ranking\": positions,\n",
    "    \"precision_at_k\": average_precision_at_k,\n",
    "    \"recall\": recall,\n",
    "    \"avg_prec@top1\": avg_top_prec,\n",
    "    \"avg_recall@top1\": avg_recall_at_top,\n",
    "    \"recall_axis\": recall_axis,\n",
    "    \"precision_axis\": average_precision,\n",
    "    \"mean_average_precision\": np.mean(average_precision),\n",
    "    \"reference_library_size\": len(X),\n",
    "    \"number_of_queries\": len(enrichment_results)\n",
    "}\n",
    "\n",
    "with open(OUT_RESUTS + \".pkl\", \"bw\") as out:\n",
    "    pickle.dump(results, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_results = pd.merge(X[\"Var1\"], enrichment_results, left_index=True, right_index=True)\n",
    "all_results = pd.merge(all_results, prec_at_top1, left_index=True, right_index=True)\n",
    "all_results = pd.merge(all_results, recall_at_top10, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_results.to_csv(OUT_RESUTS + \".csv\", index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}